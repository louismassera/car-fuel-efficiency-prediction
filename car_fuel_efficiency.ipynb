{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Louis/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2015 = pd.read_csv('dataset/2015.csv', sep=\",\")\n",
    "df_2016 = pd.read_csv('dataset/2016.csv', sep=\",\")\n",
    "df_2017 = pd.read_csv('dataset/2017.csv', sep=\",\")\n",
    "df_2018 = pd.read_csv('dataset/2018.csv', sep=\",\")\n",
    "\n",
    "df_list = [df_2015, df_2016, df_2017, df_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dico(df_to_clean, p_column=100, p_row=100):\n",
    "    df = df_to_clean.copy()\n",
    "    dico_column = (df.isnull().sum()/np.shape(df)[0]*100).to_dict()\n",
    "    dico_row = (df.isnull().sum(axis=1)/len(df.columns)*100).to_dict()\n",
    "    for key, value in dico_column.items():\n",
    "        if value >= p_column:\n",
    "            del df[key]\n",
    "    for key, value in dico_row.items():\n",
    "        if value >= p_row:\n",
    "            df.drop(key, inplace=True) \n",
    "    filtered_dico_column = (df.isnull().sum()/np.shape(df)[0]*100).to_dict()\n",
    "    filtered_dico_row = (df.isnull().sum(axis=1)/len(df.columns)*100).to_dict()\n",
    "    return df, filtered_dico_column, filtered_dico_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_list = []\n",
    "row = []\n",
    "column = []\n",
    "for i in df_list:\n",
    "    df, dico_column, dico_row = get_dico(i)\n",
    "    clean_list.append(df)\n",
    "    row.append(dico_row)\n",
    "    column.append(dico_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = [\"Comb Unrd Adj FE - Conventional Fuel\"]\n",
    "feature = []\n",
    "for k in np.arange(3):\n",
    "    L = []\n",
    "    for i in column[k].keys():\n",
    "        for j in ['FE', 'MPG', 'EPA', 'CO2', 'Guzzler', 'cost ', 'range', 'GHG', 'Smog', 'Desc']:\n",
    "            if j in i:\n",
    "                L.append(i)\n",
    "    feature.append(list(set(column[k].keys())-set(L))+predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_train = []\n",
    "for i in np.arange(3):\n",
    "    list_train.append(clean_list[i][feature[i]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = []\n",
    "column = []\n",
    "df_list = []\n",
    "\n",
    "for i in list_train:\n",
    "    df, dico_column, dico_row = get_dico(i,60,100)\n",
    "    row.append(dico_row)\n",
    "    column.append(dico_column)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = ['Mfr Name', \n",
    "               'Division', \n",
    "               'Carline', \n",
    "               'Carline Class',\n",
    "               'Verify Mfr Cd',\n",
    "               'Air Aspir Method',\n",
    "               'Index (Model Type Index)', \n",
    "               'Transmission',\n",
    "               'Trans',\n",
    "               'Drive Sys', \n",
    "               'Fuel Usage  - Conventional Fuel',\n",
    "               'Fuel Unit - Conventional Fuel',\n",
    "               'Fuel Metering Sys Cd',\n",
    "               'Car/Truck Category - Cash for Clunkers Bill.',\n",
    "               'Oil Viscosity']\n",
    "\n",
    "numerical = ['Model Year', \n",
    "             'Eng Displ', \n",
    "             '# Cyl', \n",
    "             'Intake Valves Per Cyl',\n",
    "             '# Gears',\n",
    "             'Annual Fuel1 Cost - Conventional Fuel',\n",
    "             'Exhaust Valves Per Cyl',\n",
    "             '$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) ',\n",
    "             'Max Ethanol % - Gasoline',\n",
    "             'Release Date']\n",
    "\n",
    "boolean = ['Lockup Torque Converter',\n",
    "           'Trans Creeper Gear', \n",
    "           'Cyl Deact?', \n",
    "           'Var Valve Timing?', \n",
    "           'Var Valve Lift?', \n",
    "           'Camless Valvetrain (Y or N)', \n",
    "           'Stop/Start System (Engine Management System) Code',\n",
    "           'Suppressed?', \n",
    "           'Police/Emerg?',\n",
    "           'Label Recalc?',\n",
    "           'Unique Label?']\n",
    "\n",
    "to_clean = ['Oil Viscosity']\n",
    "\n",
    "predict = [\"Comb Unrd Adj FE - Conventional Fuel\"]\n",
    "\n",
    "list_feature = categorical + predict + numerical + boolean \n",
    "list_feature_X = categorical + numerical + boolean \n",
    "\n",
    "all_categorical = categorical + boolean \n",
    "all_numerical = predict + numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2018_clean, dico_column_test, dico_row_test = get_dico(clean_list[-1],101,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat(df_list, ignore_index=True)[list_feature]\n",
    "df_test = df_2018_clean[list_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_clean(date):\n",
    "    date = str(date)\n",
    "    if date != 'nan':\n",
    "        date_convert = datetime.datetime.strptime(date, \"%d/%m/%y\").timestamp()\n",
    "    else:\n",
    "        date_convert = np.nan\n",
    "    return date_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Louis/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train['Release Date'] = df_train['Release Date'].apply(date_clean)\n",
    "df_test['Release Date'] = df_test['Release Date'].apply(date_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_numerical = df_train[numerical]\n",
    "df_test_numerical = df_test[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def fill_NaN(X_train, nbr_neighbors):\n",
    "    distances = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "    for i, x1 in enumerate(X_train):\n",
    "        for j, x2 in enumerate(X_train):\n",
    "            dist = (x1 - x2) ** 2\n",
    "            nan_mask = np.isnan(dist)\n",
    "            distances[i, j] = dist[~nan_mask].mean() * X_train.shape[1]\n",
    "\n",
    "    neighbors = np.argsort(distances, axis=1)[:, 1:]\n",
    "    n_neighbors = nbr_neighbors\n",
    "    X_train_knn = X_train.copy()\n",
    "    for feature in range(X_train.shape[1]):\n",
    "        has_missing_value = np.isnan(X_train[:, feature])\n",
    "        for row in np.where(has_missing_value)[0]:\n",
    "            neighbor_features = X_train[neighbors[row], feature]\n",
    "            non_nan_neighbors = neighbor_features[~np.isnan(neighbor_features)]\n",
    "            X_train_knn[row, feature] = non_nan_neighbors[:n_neighbors].mean()\n",
    "    \n",
    "    return X_train_knn, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filled_df(df):\n",
    "    df_categorical = df[all_categorical+predict]\n",
    "    df_numerical = df[numerical]\n",
    "    X_knn, distances = fill_NaN(df_numerical.as_matrix(), 3)\n",
    "    df_numerical_filled = pd.DataFrame(X_knn, columns=numerical)\n",
    "    df_full = pd.concat([df_numerical_filled, df_categorical],axis=1)\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train_full = get_filled_df(df_train)\n",
    "df_test_full = get_filled_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scaled(df_train, df_test, sep=True):\n",
    "    scaler = StandardScaler()\n",
    "    if sep == True:\n",
    "        scaler.fit(df_train[all_numerical])\n",
    "        df_train_numerical = pd.DataFrame(scaler.transform(df_train[all_numerical]), columns=all_numerical)\n",
    "        df_test_numerical = pd.DataFrame(scaler.transform(df_test[all_numerical]), columns=all_numerical)\n",
    "        df_train_scaled = pd.concat([df_train_numerical, df_train[all_categorical]],axis=1)\n",
    "        df_test_scaled = pd.concat([df_test_numerical, df_test[all_categorical]],axis=1)\n",
    "    else:\n",
    "        scaler.fit(df_train)\n",
    "        df_train_scaled = pd.DataFrame(scaler.transform(df_train), columns=df_train.columns)\n",
    "        df_test_scaled = pd.DataFrame(scaler.transform(df_test), columns=df_test.columns)\n",
    "    return df_train_scaled, df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dummy(df_train, df_test):\n",
    "    df_dummy = pd.get_dummies(df_train[list_feature_X])\n",
    "    df_test_dummy = pd.get_dummies(df_test[list_feature_X])\n",
    "\n",
    "    final_feature = list(set(df_dummy.columns) - (set(df_dummy.columns) - set(df_test_dummy.columns)))\n",
    "\n",
    "    X_train = df_dummy[final_feature]\n",
    "    #X_train.loc[:,'Bias'] = pd.Series(1, index=X_train.index)\n",
    "    Y_train = df_train[predict]\n",
    "    X_test = df_test_dummy[final_feature]\n",
    "    #X_test.loc[:, 'Bias'] = pd.Series(1, index=X_test.index)\n",
    "    Y_test = df_test[predict]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting the dummies and scaling afterwards\n",
    "X_train, Y_train, X_test, Y_test = get_dummy(df_train_full, df_test_full)\n",
    "X_train, X_test = get_scaled(X_train, X_test,sep=False)\n",
    "Y_train, Y_test = get_scaled(Y_train, Y_test,sep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.shape(df_test)[0]\n",
    "m = np.shape(df_train)[0]\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_data(df, stop):\n",
    "    n = np.shape(df)[0]\n",
    "    ind = np.arange(n)\n",
    "    shuffle(ind)\n",
    "    return(df.iloc[ind][:stop].reset_index(drop = True), df.iloc[ind][stop:].reset_index(drop = True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_iid, df_test_iid = select_data(df_all, stop=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train_iid_full = get_filled_df(df_train_iid)\n",
    "df_test_iid_full = get_filled_df(df_test_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_iid, Y_train_iid, X_test_iid, Y_test_iid = get_dummy(df_train_iid_full, df_test_iid_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_iid, X_test_iid = get_scaled(X_train_iid, X_test_iid,sep=False)\n",
    "Y_train_iid, Y_test_iid = get_scaled(Y_train_iid, Y_test_iid,sep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'alpha': np.logspace(-3, 3, 13)}\n",
    "grid_ridge = GridSearchCV(Ridge(), param_grid, cv=10)\n",
    "grid_ridge.fit(X_train, Y_train)\n",
    "print(grid_ridge.best_params_)\n",
    "print(grid_ridge.best_score_)\n",
    "ridge = grid_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on Ridge regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid['alpha'], grid_ridge.cv_results_['mean_test_score'], marker='o')\n",
    "plt.fill_between(param_grid['alpha'], grid_ridge.cv_results_['mean_test_score'] \n",
    "                 + grid_ridge.cv_results_['std_test_score'], \n",
    "                 grid_ridge.cv_results_['mean_test_score'] - \n",
    "                 grid_ridge.cv_results_['std_test_score'], \n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Ridge coefficent', fontsize=18)\n",
    "plt.xlabel('coefficient n°', fontsize=16)\n",
    "plt.ylabel('value', fontsize=16)\n",
    "plt.scatter(np.arange(len(ridge.coef_[0])), ridge.coef_, c=np.sign(ridge.coef_), cmap=\"bwr_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 13)}\n",
    "grid_lasso = GridSearchCV(Lasso(), param_grid, cv=10)\n",
    "grid_lasso.fit(X_train, Y_train)\n",
    "print(grid_lasso.best_params_)\n",
    "print(grid_lasso.best_score_)\n",
    "lasso = grid_lasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on Lasso regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid['alpha'], grid_lasso.cv_results_['mean_test_score'], marker='o')\n",
    "plt.fill_between(param_grid['alpha'], grid_lasso.cv_results_['mean_test_score']\n",
    "                 + grid_lasso.cv_results_['std_test_score'], \n",
    "                 grid_lasso.cv_results_['mean_test_score']\n",
    "                 - grid_lasso.cv_results_['std_test_score'], \n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Lasso coefficent', fontsize=18)\n",
    "plt.xlabel('coefficient n°', fontsize=16)\n",
    "plt.ylabel('value', fontsize=16)\n",
    "plt.scatter(np.arange(len(lasso.coef_)), lasso.coef_, c=np.sign(lasso.coef_), cmap=\"bwr_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'alpha': np.logspace(-2, 3, 13)}\n",
    "grid_elastic_net = GridSearchCV(ElasticNet(), param_grid, cv=10)\n",
    "grid_elastic_net.fit(X_train, Y_train)\n",
    "print(grid_elastic_net.best_params_)\n",
    "print(grid_elastic_net.best_score_)\n",
    "elastic_net = grid_elastic_net.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on ElasticNet regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid['alpha'], grid_elastic_net.cv_results_['mean_test_score'], \n",
    "         marker='o')\n",
    "plt.fill_between(param_grid['alpha'], grid_elastic_net.cv_results_['mean_test_score']\n",
    "                 + grid_elastic_net.cv_results_['std_test_score'], \n",
    "                 grid_elastic_net.cv_results_['mean_test_score']\n",
    "                 - grid_elastic_net.cv_results_['std_test_score'],\n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of our best linear model, with and without the iid assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(best_param, X_train, X_test, assumption_iid = False, type='r'):\n",
    "    if type == 'r':\n",
    "        model_evaluate = Ridge(alpha=best_param)\n",
    "    elif type == 'l':\n",
    "        model_evaluate = Lasso(alpha=best_param)\n",
    "    else:\n",
    "        model_evaluate = ElasticNet(alpha=best_param)\n",
    "        \n",
    "    if assumption_iid == False:\n",
    "        model_evaluate.fit(X_train, Y_train)\n",
    "        score = model_evaluate.score(X_test, Y_test)\n",
    "    else:\n",
    "        model_evaluate.fit(X_train_iid, Y_train_iid)\n",
    "        score = model_evaluate.score(X_test_iid, Y_test_iid)\n",
    "   \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = evaluate(grid_ridge.best_params_['alpha'], X_train, X_test)\n",
    "print(score)\n",
    "score_iid = evaluate(grid_ridge.best_params_['alpha'], X_train, X_test, assumption_iid = True)\n",
    "print(score_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting polynomial features of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures()\n",
    "categorical_dummies = list(set(X_train.columns) - set(X_train[numerical].columns))\n",
    "X_train_categorical_poly = X_train[categorical_dummies]\n",
    "X_train_numerical_poly = pd.DataFrame(poly.fit_transform(X_train[numerical]))\n",
    "X_test_numerical_poly = pd.DataFrame(poly.transform(X_test[numerical]))\n",
    "X_train_poly = pd.concat([X_train_numerical_poly, X_train[categorical_dummies]], axis=1)\n",
    "X_test_poly = pd.concat([X_test_numerical_poly, X_test[categorical_dummies]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_poly = {'alpha': np.logspace(-3, 3, 13)}\n",
    "grid_ridge_poly = GridSearchCV(Ridge(), param_grid_poly, cv=10)\n",
    "grid_ridge_poly.fit(X_train_poly, Y_train)\n",
    "print(grid_ridge_poly.best_params_)\n",
    "print(grid_ridge_poly.best_score_)\n",
    "ridge_poly = grid_ridge_poly.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on Ridge regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid['alpha'], grid_ridge_poly.cv_results_['mean_test_score'], marker='o')\n",
    "plt.fill_between(param_grid['alpha'], grid_ridge_poly.cv_results_['mean_test_score'] \n",
    "                 + grid_ridge_poly.cv_results_['std_test_score'], \n",
    "                 grid_ridge_poly.cv_results_['mean_test_score'] - \n",
    "                 grid_ridge_poly.cv_results_['std_test_score'], \n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Ridge coefficent', fontsize=18)\n",
    "plt.xlabel('coefficient n°', fontsize=16)\n",
    "plt.ylabel('value', fontsize=16)\n",
    "plt.scatter(np.arange(len(ridge_poly.coef_[0])), ridge_poly.coef_, c=np.sign(ridge_poly.coef_), cmap=\"bwr_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid_poly = {'alpha': np.logspace(-3, 3, 13)}\n",
    "grid_lasso_poly = GridSearchCV(Lasso(normalize=True), param_grid_poly, cv=10)\n",
    "grid_lasso_poly.fit(X_train_poly, Y_train)\n",
    "print(grid_lasso_poly.best_params_)\n",
    "print(grid_lasso_poly.best_score_)\n",
    "lasso_poly = grid_lasso_poly.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on Lasso regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid_poly['alpha'], grid_lasso_poly.cv_results_['mean_test_score'], marker='o')\n",
    "plt.fill_between(param_grid_poly['alpha'], grid_lasso_poly.cv_results_['mean_test_score']\n",
    "                 + grid_lasso_poly.cv_results_['std_test_score'], \n",
    "                 grid_lasso_poly.cv_results_['mean_test_score']\n",
    "                 - grid_lasso_poly.cv_results_['std_test_score'], \n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_poly = {'alpha': np.logspace(-1, 3, 13)}\n",
    "grid_elastic_net_poly = GridSearchCV(ElasticNet(), param_grid_poly, cv=10)\n",
    "grid_elastic_net_poly.fit(X_train_poly, Y_train)\n",
    "print(grid_elastic_net_poly.best_params_)\n",
    "print(grid_elastic_net_poly.best_score_)\n",
    "elastic_net_poly = grid_elastic_net_poly.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of alpha on ElasticNet regression', fontsize=20)\n",
    "plt.xlabel('alpha', fontsize=18)\n",
    "plt.ylabel('validation score', fontsize=18)\n",
    "plt.plot(param_grid_poly['alpha'], grid_elastic_net_poly.cv_results_['mean_test_score'], \n",
    "         marker='o')\n",
    "plt.fill_between(param_grid_poly['alpha'], grid_elastic_net_poly.cv_results_['mean_test_score']\n",
    "                 + grid_elastic_net_poly.cv_results_['std_test_score'], \n",
    "                 grid_elastic_net_poly.cv_results_['mean_test_score']\n",
    "                 - grid_elastic_net_poly.cv_results_['std_test_score'],\n",
    "                 facecolor='blue', \n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## No scaling\n",
    "X_train, Y_train, X_test, Y_test = get_dummy(df_train_full, df_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting polynomial\n",
    "poly = PolynomialFeatures()\n",
    "categorical_dummies = list(set(X_train.columns) - set(X_train[numerical].columns))\n",
    "X_train_numerical_poly = pd.DataFrame(poly.fit_transform(X_train[numerical]))\n",
    "X_test_numerical_poly = pd.DataFrame(poly.transform(X_test[numerical]))\n",
    "X_train_poly = pd.concat([X_train_numerical_poly, X_train[categorical_dummies]], axis=1)\n",
    "X_test_poly = pd.concat([X_test_numerical_poly, X_test[categorical_dummies]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_model = XGBRegressor(n_estimators = 300)\n",
    "m = int(np.shape(X_train)[0]/10)\n",
    "X_train_val = X_train[:m]\n",
    "Y_train_val = Y_train[:m]\n",
    "X_train_tr = X_train[m:]\n",
    "Y_train_tr = Y_train[m:]\n",
    "grad_model.fit(X_train_tr, Y_train_tr)\n",
    "print(grad_model.score(X_train_val, Y_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(n_estimators = 300)\n",
    "m = int(np.shape(X_train)[0]/10)\n",
    "X_train_poly_val = X_train_poly[:m]\n",
    "Y_train_poly_val = Y_train[:m]\n",
    "X_train_poly_tr = X_train_poly[m:]\n",
    "Y_train_tr = Y_train[m:]\n",
    "final_model.fit(X_train_poly_tr, Y_train_tr)\n",
    "print(final_model.score(X_train_poly_val, Y_train_poly_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures()\n",
    "categorical_dummies = list(set(X_train_iid.columns) - set(X_train_iid[numerical].columns))\n",
    "X_train_iid_categorical_poly = X_train_iid[categorical_dummies]\n",
    "X_train_iid_numerical_poly = pd.DataFrame(poly.fit_transform(X_train_iid[numerical]))\n",
    "X_test_iid_numerical_poly = pd.DataFrame(poly.transform(X_test_iid[numerical]))\n",
    "X_train_iid_poly = pd.concat([X_train_iid_numerical_poly, X_train_iid[categorical_dummies]], axis=1)\n",
    "X_test_iid_poly = pd.concat([X_test_iid_numerical_poly, X_test_iid[categorical_dummies]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(n_estimators = 300)\n",
    "final_model.fit(X_train_poly, Y_train)\n",
    "print('Score without iid assumption :', final_model.score(X_test_poly, Y_test))\n",
    "\n",
    "final_model_iid = XGBRegressor(n_estimators = 300)\n",
    "final_model_iid.fit(X_train_iid_poly, Y_train_iid)\n",
    "print('Score with iid assumption :', final_model_iid.score(X_test_iid_poly, Y_test_iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 4 : Feature Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "dico = final_model.booster().get_score(importance_type='weight')\n",
    "for key, value in dico.items():\n",
    "    if key in str(np.arange(100)):\n",
    "        key = int(key)\n",
    "    L.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_filtered = X_train_poly[L]\n",
    "X_test_filtered = X_test_poly[L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(n_estimators = 300)\n",
    "final_model.fit(X_train_filtered, Y_train)\n",
    "print('Score without iid assumption :', final_model.score(X_test_filtered, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_sparse = []\n",
    "dico = final_model.booster().get_score(importance_type='weight')\n",
    "for key, value in dico.items():\n",
    "    if key in str(np.arange(100)):\n",
    "        key = int(key)\n",
    "    if value > 10:\n",
    "        L_sparse.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse = X_train_poly[L_sparse]\n",
    "X_test_sparse = X_test_poly[L_sparse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(n_estimators = 300)\n",
    "final_model.fit(X_train_sparse, Y_train)\n",
    "print('Score without iid assumption :', final_model.score(X_test_sparse, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
